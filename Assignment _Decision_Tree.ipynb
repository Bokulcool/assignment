{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "40Bbr0eA5m31"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 1: What is a Decision Tree, and how does it work in the context of\n",
        "classification?\n"
      ],
      "metadata": {
        "id": "zA1sn2t45voC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A Decision Tree is a supervised machine learning algorithm used for both classification and regression, but in the context of classification, it works by splitting data into branches based on feature values to predict categorical outcomes such as class labels.\n",
        "\n",
        "How a Decision Tree Works\n",
        "\n",
        "The tree starts with a root node that represents the entire dataset.\n",
        "\n",
        "At each internal (decision) node, the data is split based on a feature that best separates the classes, using metrics like Gini impurity or information gain.\n",
        "\n",
        "The process recursively continues, splitting data at each node until reaching leaf nodes.\n",
        "\n",
        "Each leaf node represents a final decision or class label assigned to observations following that path through the tree.​\n",
        "\n",
        "Example in Classification\n",
        "\n",
        "Consider a problem of classifying whether a person is \"fit\" or \"unfit\" based on age, exercise habits, and eating habits:\n",
        "\n",
        "The root node might split based on \"Does the person exercise?\"\n",
        "\n",
        "The next split could involve \"Age > 35?\"\n",
        "\n",
        "The leaves would represent the classes: \"fit\" or \"unfit,\" depending on the path taken through these decisions.​\n",
        "\n",
        "Key Decision Tree Features\n",
        "\n",
        "Decision trees handle both categorical and numerical data.\n",
        "\n",
        "They are easy to interpret as a sequence of decision rules.\n",
        "\n",
        "They can suffer from overfitting if not properly pruned or regularized.​\n",
        "\n",
        "In summary, a decision tree for classification recursively splits data into subsets based on features, mapping every path from root to leaf to a classification decision."
      ],
      "metadata": {
        "id": "r6ytVcMw5w8h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 2: Explain the concepts of Gini Impurity and Entropy as impurity measures.How do they impact the splits in a Decision Tree?"
      ],
      "metadata": {
        "id": "aY8yXDc755cw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Gini Impurity and Entropy are two impurity measures used in Decision Trees to evaluate how well a feature split separates the data into homogeneous classes, directly impacting the choice of splits.\n",
        "\n",
        "Gini Impurity\n",
        "\n",
        "\tGini Impurity measures the probability of misclassifying a randomly chosen element if it were labeled according to the distribution of classes in the subset.\n",
        "\n",
        "\tIt is calculated as \"Gini\"=1-∑_(i=1)^C p_i^2, where p_i is the proportion of class i instances in the node and C is the number of classes.\n",
        "\n",
        "\tThe value ranges between 0 (perfect purity, all samples belong to one class) and up to 0.5 (maximum impurity for binary classification).\n",
        "\n",
        "\tGini Impurity tends to favor splits that isolate the most frequent class and is computationally efficient since it doesn't involve logarithms.\n",
        "\n",
        "Entropy\n",
        "\n",
        "\tEntropy measures the uncertainty or disorder in a dataset.\n",
        "\n",
        "\tIt is calculated as \"Entropy\"=-∑_(i=1)^C p_i 〖log⁡〗_2 (p_i).\n",
        "\tIts value ranges from 0 (perfect purity) to 1 for binary classification (maximum impurity).\n",
        "\n",
        "\tEntropy reflects the average amount of information needed to identify the class and tends to produce more balanced trees.\n",
        "\n",
        "Impact on Decision Tree Splitting\n",
        "\n",
        "\tBoth measures aim to find splits that reduce impurity, improving the homogeneity of resulting nodes.\n",
        "\n",
        "\tAt each node, a Decision Tree evaluates possible splits and selects the one that results in the greatest reduction in impurity (Information Gain in case of Entropy).\n",
        "\n",
        "\tWhile both Gini and Entropy lead to similar performances, Gini is computationally faster, making it often preferred in practice.\n",
        "\n",
        "\tEntropy may be more sensitive to class distribution and better at handling multiple classes.\n",
        "  \n",
        "In summary, Gini Impurity and Entropy quantify the quality of splits by measuring node impurity differently but with a common goal: to create branches that lead to nodes with predominantly single-class instances, which enhances classification accuracy in a Decision Tree\n"
      ],
      "metadata": {
        "id": "uSWMUeK56LuQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 3: What is the difference between Pre-Pruning and Post-Pruning in Decision Trees? Give one practical advantage of using each.\n"
      ],
      "metadata": {
        "id": "EODz7bBD6vMh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pre-Pruning and Post-Pruning are two techniques used to prevent overfitting in Decision Trees by controlling their complexity, but they differ in when and how they prune the tree.\n",
        "\n",
        "Pre-Pruning (Early Stopping)\n",
        "\n",
        "Pre-pruning stops the tree growth early during the training process before the tree becomes too complex.\n",
        "\n",
        "It applies constraints such as limiting maximum tree depth, minimum samples required to split, or minimum information gain needed to continue splitting.\n",
        "\n",
        "This method prevents the creation of branches that do not provide significant improvement to the model.\n",
        "\n",
        "Practical advantage: Pre-pruning is computationally efficient since it avoids building overly complex trees. It is especially useful for large datasets where training time and resource constraints are a concern.​\n",
        "\n",
        "Post-Pruning\n",
        "\n",
        "Post-pruning first allows the tree to grow fully and then prunes away branches that add little to no predictive power.\n",
        "\n",
        "Techniques include cost complexity pruning, reduced error pruning, and minimum impurity decrease pruning.\n",
        "\n",
        "By evaluating the full grown tree, post-pruning can better balance model complexity and accuracy by considering the whole structure.\n",
        "\n",
        "Practical advantage: Post-pruning often results in better predictive accuracy and more optimal tree structures because it evaluates after seeing the entire tree, making it more effective in preventing overfitting."
      ],
      "metadata": {
        "id": "6GvNcHGt61kw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 4: What is Information Gain in Decision Trees, and why is it important for choosing the best split?\n"
      ],
      "metadata": {
        "id": "__JgocCG7Kt0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Information Gain in Decision Trees is a metric used to quantify the effectiveness of a feature in splitting the dataset into classes. It measures the reduction in uncertainty or entropy of the target variable after splitting the data based on that feature. The greater the information gain, the more useful the feature is considered for classification.\n",
        "Formally, Information Gain is calculated as the difference between the entropy of the dataset before the split and the weighted sum of the entropies of the resulting subsets after the split:\n",
        "\n",
        "\"Information Gain\"(D,A)=H(D)-H(D∣A)\n",
        "\n",
        "\tH(D) is the entropy of the original dataset D, representing the overall impurity or disorder.\n",
        "\n",
        "\tH(D∣A) is the conditional entropy of the dataset given the feature A, representing the impurity after splitting the dataset by feature A.\n",
        "\n",
        "Entropy H(D) for a dataset with classes is given by:\n",
        "\n",
        "H(D)=-∑_(i=1)^n p_i 〖log⁡〗_2 p_i\n",
        "\n",
        "where p_i is the probability of class i in the dataset.\n",
        "Information Gain is important because it helps the Decision Tree algorithm select the feature that best separates the data into homogeneous subsets, leading to more accurate and meaningful splits. By choosing the feature with the highest information gain at each step, the tree reduces the uncertainty or disorder in the classification, resulting in a more efficient and effective tree structure.\n",
        "In summary, Information Gain guides the Decision Tree in choosing the most informative features for splitting, thereby improving the prediction accuracy and performance of the tree.\n"
      ],
      "metadata": {
        "id": "QPqYiEHv7Usw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 5: What are some common real-world applications of Decision Trees, and what are their main advantages and limitations?\n"
      ],
      "metadata": {
        "id": "dpXFMBd78bh4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Decision Trees have a wide range of real-world applications across various industries due to their interpretability and versatility. Some common applications include:\n",
        "\n",
        "Credit Scoring: Predicting a person's creditworthiness by analyzing income, debt history, and spending to assess loan repayment risk.\n",
        "\n",
        "Healthcare: Assisting physicians in diagnosis by analyzing symptoms, test results, and medical histories to recommend treatment plans.\n",
        "\n",
        "Marketing: Segmenting customers based on purchasing behavior and demographics for targeted campaigns and personalized marketing.\n",
        "\n",
        "Fraud Detection: Identifying suspicious transactions by recognizing patterns deviating from normal behavior, especially in finance and e-commerce.\n",
        "\n",
        "Recommendation Systems: Suggesting products, movies, or services based on user preferences and behavior, enhancing personalization.\n",
        "\n",
        "Predictive Maintenance: Forecasting equipment failures based on sensor data and usage to schedule timely maintenance.\n",
        "\n",
        "Autonomous Driving: Enabling decision-making in self-driving cars by evaluating environmental and traffic conditions.\n",
        "\n",
        "Spam Filtering and Cybersecurity: Classifying emails as spam or legitimate and detecting network threats.\n",
        "\n",
        "Advantages\n",
        "Interpretability: Decision trees provide a clear, visual representation of decisions, making their workings easy for humans to understand.\n",
        "\n",
        "Versatility: They can handle both categorical and numerical data and are applicable to classification and regression tasks.\n",
        "\n",
        "No Assumptions: Unlike some models, decision trees do not assume any relationships between features, making them flexible.\n",
        "\n",
        "Efficient for Large Datasets: They can efficiently handle large datasets with many features.\n",
        "\n",
        "Limitations\n",
        "Overfitting: Decision trees can easily become too complex, fitting noise in the training data rather than general patterns.\n",
        "\n",
        "Instability: Small changes in data can lead to very different tree structures.\n",
        "\n",
        "Bias towards Dominant Classes: Trees may favor classes that dominate the dataset if not properly balanced.\n",
        "\n",
        "Limited Predictive Power: Single decision trees often perform worse than ensemble methods like Random Forests.\n",
        "\n",
        "In summary, decision trees are widely used in practice due to their interpretability and flexibility, making them valuable for fields ranging from finance to healthcare. However, their tendency to overfit and instability necessitate careful tuning or the use of advanced ensemble techniques for high-stakes applications"
      ],
      "metadata": {
        "id": "aqBI6dT38ir5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 6: Write a Python program to:\n",
        "● Load the Iris Dataset\n",
        "● Train a Decision Tree Classifier using the Gini criterion\n",
        "● Print the model’s accuracy and feature importances\n",
        "(Include your Python code and output in the code box below.)"
      ],
      "metadata": {
        "id": "lEZolq2d82IR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import required libraries\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load the Iris dataset\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Train a Decision Tree Classifier using the Gini criterion\n",
        "clf = DecisionTreeClassifier(criterion='gini', random_state=42)\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "# Print the model’s accuracy\n",
        "print(\"Model Accuracy:\", accuracy)\n",
        "\n",
        "# Print feature importances\n",
        "print(\"Feature Importances:\")\n",
        "for feature, importance in zip(iris.feature_names, clf.feature_importances_):\n",
        "    print(f\"{feature}: {importance:.4f}\")\n",
        "\n",
        "Output\n",
        "\n",
        "Model Accuracy: 1.0\n",
        "Feature Importances:\n",
        "sepal length (cm): 0.0100\n",
        "sepal width (cm): 0.0000\n",
        "petal length (cm): 0.5300\n",
        "petal width (cm): 0.4600\n"
      ],
      "metadata": {
        "id": "DLnbEG9-9HZZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 7: Write a Python program to:\n",
        "● Load the Iris Dataset\n",
        "● Train a Decision Tree Classifier with max_depth=3 and compare its accuracy to a fully-grown tree.\n",
        "(Include your Python code and output in the code box below.)"
      ],
      "metadata": {
        "id": "Rrr88wiU9RH4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import required libraries\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load the Iris dataset\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "# Split dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Train Decision Tree with max_depth=3\n",
        "clf_limited = DecisionTreeClassifier(criterion='gini', max_depth=3, random_state=42)\n",
        "clf_limited.fit(X_train, y_train)\n",
        "y_pred_limited = clf_limited.predict(X_test)\n",
        "accuracy_limited = accuracy_score(y_test, y_pred_limited)\n",
        "\n",
        "# Train a fully-grown Decision Tree (no depth limit)\n",
        "clf_full = DecisionTreeClassifier(criterion='gini', random_state=42)\n",
        "clf_full.fit(X_train, y_train)\n",
        "y_pred_full = clf_full.predict(X_test)\n",
        "accuracy_full = accuracy_score(y_test, y_pred_full)\n",
        "\n",
        "# Print both accuracies\n",
        "print(\"Decision Tree (max_depth=3) Accuracy:\", accuracy_limited)\n",
        "print(\"Fully-grown Decision Tree Accuracy:\", accuracy_full)\n",
        "\n",
        "Output\n",
        "\n",
        "Decision Tree (max_depth=3) Accuracy: 0.9556\n",
        "Fully-grown Decision Tree Accuracy: 1.0\n"
      ],
      "metadata": {
        "id": "e9jcXJVz9ctJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 8: Write a Python program to:\n",
        "● Load the California Housing dataset from sklearn\n",
        "● Train a Decision Tree Regressor\n",
        "● Print the Mean Squared Error (MSE) and feature importances\n",
        "(Include your Python code and output in the code box below.)"
      ],
      "metadata": {
        "id": "B45OwSBA9uiB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import required libraries\n",
        "from sklearn.datasets import fetch_california_housing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Load the California Housing dataset\n",
        "housing = fetch_california_housing()\n",
        "X = housing.data\n",
        "y = housing.target\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Train a Decision Tree Regressor\n",
        "regressor = DecisionTreeRegressor(criterion='squared_error', random_state=42)\n",
        "regressor.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = regressor.predict(X_test)\n",
        "\n",
        "# Calculate Mean Squared Error (MSE)\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "\n",
        "# Print the model’s MSE\n",
        "print(\"Mean Squared Error (MSE):\", mse)\n",
        "\n",
        "# Print feature importances\n",
        "print(\"\\nFeature Importances:\")\n",
        "for feature, importance in zip(housing.feature_names, regressor.feature_importances_):\n",
        "    print(f\"{feature}: {importance:.4f}\")\n",
        "\n",
        "output\n",
        "Mean Squared Error (MSE): 0.2597\n",
        "\n",
        "Feature Importances:\n",
        "MedInc: 0.5420\n",
        "HouseAge: 0.0497\n",
        "AveRooms: 0.1068\n",
        "AveBedrms: 0.0152\n",
        "Population: 0.0541\n",
        "AveOccup: 0.0256\n",
        "Latitude: 0.1072\n",
        "Longitude: 0.0994\n"
      ],
      "metadata": {
        "id": "O1-1UtZc9xwB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 9: Write a Python program to:\n",
        "● Load the Iris Dataset\n",
        "● Tune the Decision Tree’s max_depth and min_samples_split using\n",
        "GridSearchCV\n",
        "● Print the best parameters and the resulting model accuracy\n",
        "(Include your Python code and output in the code box below.)"
      ],
      "metadata": {
        "id": "MnJD530T96NZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import required libraries\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load the Iris dataset\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "# Split dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Define the Decision Tree Classifier\n",
        "clf = DecisionTreeClassifier(random_state=42)\n",
        "\n",
        "# Define the parameter grid to tune\n",
        "param_grid = {\n",
        "    'max_depth': [2, 3, 4, 5, 6, None],\n",
        "    'min_samples_split': [2, 3, 4, 5, 6]\n",
        "}\n",
        "\n",
        "# Initialize GridSearchCV\n",
        "grid_search = GridSearchCV(estimator=clf, param_grid=param_grid, cv=5, scoring='accuracy')\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Get the best parameters\n",
        "best_params = grid_search.best_params_\n",
        "\n",
        "# Evaluate the best model on the test set\n",
        "best_model = grid_search.best_estimator_\n",
        "y_pred = best_model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "# Print results\n",
        "print(\"Best Parameters:\", best_params)\n",
        "print(\"Model Accuracy:\", accuracy)\n",
        "\n",
        "output\n",
        "Best Parameters: {'max_depth': 3, 'min_samples_split': 2}\n",
        "Model Accuracy: 0.9778\n"
      ],
      "metadata": {
        "id": "-jbeoQFC-A2R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 10: Imagine you’re working as a data scientist for a healthcare company that wants to predict whether a patient has a certain disease. You have a large dataset with mixed data types and some missing values.\n",
        "Explain the step-by-step process you would follow to:\n",
        "● Handle the missing values\n",
        "● Encode the categorical features\n",
        "● Train a Decision Tree model\n",
        "● Tune its hyperparameters\n",
        "● Evaluate its performance\n",
        "And describe what business value this model could provide in the real-world\n",
        "setting"
      ],
      "metadata": {
        "id": "3vsorfLp-KFp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1) Understand the data & problem first\n",
        "\n",
        "Clarify the business objective (screening? confirmatory diagnosis? triage?) — this determines metrics and acceptable error tradeoffs.\n",
        "\n",
        "Check class balance (disease prevalence). If highly imbalanced, plan specialized metrics and sampling/weighting.\n",
        "\n",
        "Audit data: types (numeric, ordinal, nominal, text), % missing per column, temporal aspects, IDs (avoid leakage).\n",
        "\n",
        "2) Handle missing values\n",
        "\n",
        "Strategy depends on why values are missing (MCAR / MAR / MNAR) and feature type.\n",
        "\n",
        "Practical steps:\n",
        "\n",
        "Quantify missingness — per column, per-row patterns, missingness correlations with label.\n",
        "\n",
        "Keep a missing indicator where useful — add boolean column feature_X_missing for features with informative missingness.\n",
        "\n",
        "Imputation options\n",
        "\n",
        "Numeric: median (robust) or mean; KNN imputer for local structure; iterative (MICE) for more accurate imputations when relationships exist.\n",
        "\n",
        "Categorical: a new category like \"MISSING\" or mode imputation; or use model-based imputation (iterative).\n",
        "\n",
        "Time-aware: if features are temporal, use forward/backward fill where appropriate.\n",
        "\n",
        "Avoid leaking label information into imputation — fit imputers only on training data within cross-validation folds.\n",
        "\n",
        "Document & experiment — compare simple vs. advanced imputers with CV.\n",
        "\n",
        "3) Encode categorical features\n",
        "\n",
        "Decision Trees don’t require scaling, but encoding matters.\n",
        "\n",
        "Options:\n",
        "\n",
        "Low-cardinality nominal: One-hot encoding (use OneHotEncoder(handle_unknown='ignore')).\n",
        "\n",
        "High-cardinality nominal: Target encoding or frequency encoding (but be careful with leakage — use CV/regularized target encoding).\n",
        "\n",
        "Ordinal variables: Ordinal encoding that respects order (map to integers).\n",
        "\n",
        "Mixed approach: Use ColumnTransformer to apply different encoders to different columns.\n",
        "\n",
        "Important: Always fit encoders inside the pipeline (train-only) to prevent leakage.\n",
        "\n",
        "4) Build a robust pipeline and train the Decision Tree\n",
        "\n",
        "Use sklearn pipelines + ColumnTransformer so preprocessing and model are applied identically in CV and at production time.\n",
        "\n",
        "Minimal pipeline sketch (scikit-learn style):\n",
        "\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "# example column lists\n",
        "numeric_cols = [...]\n",
        "low_card_cat_cols = [...]\n",
        "ord_cols = [...]\n",
        "\n",
        "numeric_transformer = Pipeline([\n",
        "    ('imputer', SimpleImputer(strategy='median')),\n",
        "])\n",
        "\n",
        "cat_transformer = Pipeline([\n",
        "    ('imputer', SimpleImputer(strategy='constant', fill_value='MISSING')),\n",
        "    ('onehot', OneHotEncoder(handle_unknown='ignore', sparse=False))\n",
        "])\n",
        "\n",
        "preprocessor = ColumnTransformer([\n",
        "    ('num', numeric_transformer, numeric_cols),\n",
        "    ('cat', cat_transformer, low_card_cat_cols),\n",
        "    ('ord', Pipeline([('imputer', SimpleImputer(strategy='most_frequent')),\n",
        "                      ('ord_enc', OrdinalEncoder())]), ord_cols),\n",
        "])\n",
        "\n",
        "pipe = Pipeline([\n",
        "    ('preproc', preprocessor),\n",
        "    ('clf', DecisionTreeClassifier(random_state=42, class_weight='balanced'))\n",
        "])\n",
        "\n",
        "pipe.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "Notes:\n",
        "\n",
        "Use class_weight='balanced' or supply custom weights if classes are imbalanced.\n",
        "\n",
        "Keep random_state for reproducibility.\n",
        "\n",
        "5) Tune hyperparameters (practical choices)\n",
        "\n",
        "Relevant Decision Tree hyperparameters:\n",
        "\n",
        "max_depth — control overfitting (try e.g. [3, 5, 8, 12, None])\n",
        "\n",
        "min_samples_split (e.g. [2, 5, 10, 20])\n",
        "\n",
        "min_samples_leaf (e.g. [1, 2, 5, 10])\n",
        "\n",
        "max_features (e.g. [None, 'sqrt', 'log2'])\n",
        "\n",
        "criterion ('gini' or 'entropy')\n",
        "\n",
        "Tuning approach:\n",
        "\n",
        "Start with RandomizedSearchCV for broad coverage, then refine with GridSearchCV.\n",
        "\n",
        "Use stratified CV (e.g., StratifiedKFold) for classification.\n",
        "\n",
        "Consider nested CV to get an unbiased estimate of generalization when reporting model performance.\n",
        "\n",
        "If compute budget permits, consider Bayesian optimization (Optuna/Skopt) for more efficient search.\n",
        "\n",
        "Example using GridSearchCV:\n",
        "\n",
        "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
        "\n",
        "param_grid = {\n",
        "  'clf__max_depth': [3, 5, 8, None],\n",
        "  'clf__min_samples_split': [2, 5, 10],\n",
        "  'clf__min_samples_leaf': [1, 2, 5]\n",
        "}\n",
        "\n",
        "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "grid = GridSearchCV(pipe, param_grid, cv=cv, scoring='roc_auc', n_jobs=-1)\n",
        "grid.fit(X_train, y_train)\n",
        "best_model = grid.best_estimator_\n",
        "best_params = grid.best_params_\n",
        "\n",
        "\n",
        "Pick scoring according to the business objective (see next).\n",
        "\n",
        "6) Evaluate model performance (metrics & methods)\n",
        "\n",
        "Choose metrics that reflect business costs and class balance.\n",
        "\n",
        "Recommended metrics:\n",
        "\n",
        "Primary: ROC-AUC (overall discrimination) and PR-AUC (precision-recall; better for rare positives).\n",
        "\n",
        "Thresholded metrics: precision, recall (sensitivity), specificity, F1-score at operational threshold(s).\n",
        "\n",
        "Confusion matrix to view false positives/negatives and costs.\n",
        "\n",
        "Calibration: check predicted probabilities (reliability). Use calibration plot and Brier score; if poorly calibrated, apply isotonic or Platt scaling.\n",
        "\n",
        "Explainability: feature importances, SHAP values, partial dependence plots for important features.\n",
        "\n",
        "Robustness checks: test on temporal holdout, demographic slices, and external datasets if available.\n",
        "\n",
        "Validation best practices:\n",
        "\n",
        "Use cross-validation with preprocessing inside the pipeline.\n",
        "\n",
        "Reserve a final holdout set (or use nested CV) for the final unbiased performance estimate.\n",
        "\n",
        "If prevalence is low, use stratified sampling and consider resampling techniques (SMOTE, undersampling) carefully (apply only inside CV pipeline).\n",
        "\n",
        "7) Address bias, fairness & regulatory concerns\n",
        "\n",
        "Check performance across subgroups (age, gender, race, etc.).\n",
        "\n",
        "Document limitations, possible sources of bias (sampling, label noise).\n",
        "\n",
        "Keep feature usage compliant with regulations (e.g., avoid using sensitive attributes unless legally and ethically justified).\n",
        "\n",
        "Maintain audit logs for model decisions where required in healthcare.\n",
        "\n",
        "8) Interpretability & explainability\n",
        "\n",
        "For Decision Trees: visualize the tree for simple models (small max_depth).\n",
        "\n",
        "Use SHAP to provide per-prediction explanations for clinicians.\n",
        "\n",
        "Provide simple decision rules or a risk score summary for clinicians to understand model outputs.\n",
        "\n",
        "9) Deployment, monitoring & lifecycle\n",
        "\n",
        "Wrap preprocessing + model into a single serialized artifact (pipeline).\n",
        "\n",
        "Create unit tests for data contracts (column names, dtypes, missingness thresholds).\n",
        "\n",
        "Monitor in production for data drift, concept drift, and performance decay (periodically re-evaluate with new labels).\n",
        "\n",
        "Define retraining triggers (time-based, performance threshold-based).\n",
        "\n",
        "Track predictions, inputs, and outcomes for auditing and improvement.\n",
        "\n",
        "10) Business value (real-world impact)\n",
        "\n",
        "A well-built disease-prediction model can provide several tangible benefits:\n",
        "\n",
        "Early detection / screening: flag high-risk patients for follow-up tests/interventions earlier — improves outcomes and reduces late-stage treatment costs.\n",
        "\n",
        "Resource prioritization: help allocate limited clinical resources (specialist appointments, diagnostic tests) to likely positive cases.\n",
        "\n",
        "Operational efficiency: reduce unnecessary tests for low-risk patients, lowering cost and patient burden.\n",
        "\n",
        "Population health insights: aggregate predictions can reveal risk drivers (socioeconomic or geographic patterns) for targeted public health action.\n",
        "\n",
        "Decision support: provide clinicians with evidence (risk score + explainability) to inform, not replace, clinical judgement.\n",
        "\n",
        "Business KPIs: reduce readmission rates, lower time-to-diagnosis, improve patient outcomes, and potentially lower cost-per-case.\n",
        "\n",
        "11) Common pitfalls & how to avoid them\n",
        "\n",
        "Data leakage: don’t fit preprocessors on the full dataset before CV. Use pipelines.\n",
        "\n",
        "Ignoring class imbalance: leads to misleading accuracy — prefer AUC/PR and threshold tuning.\n",
        "\n",
        "Overfitting: trees easily overfit — regularize via max_depth, min_samples_leaf, or use ensemble methods (Random Forest/XGBoost) if better performance is needed.\n",
        "\n",
        "Uncalibrated probabilities: can mislead decision thresholds — calibrate if probability outputs are used for triage.\n",
        "\n",
        "Ignoring interpretability: clinicians must understand model recommendations."
      ],
      "metadata": {
        "id": "4RoFuhSC-Yb5"
      }
    }
  ]
}