{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vc1lxhnxNNrQ"
      },
      "outputs": [],
      "source": [
        "Question 1 : What is the fundamental idea behind ensemble techniques? How does\n",
        "bagging differ from boosting in terms of approach and objective?"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The fundamental idea behind ensemble techniques is to combine multiple models, or base learners, to create a stronger, more accurate final prediction model. Ensemble methods improve performance by aggregating the strengths of several models rather than relying on a single one, thereby reducing errors like bias and variance.\n",
        "\n",
        "Bagging (Bootstrap Aggregating) and Boosting are two primary ensemble techniques that differ in their approach and objective:\n",
        "\n",
        "Approach:\n",
        "\n",
        "Bagging trains multiple models independently and in parallel on different random subsets (bootstrapped samples) of the training data. Each model is built without regard to the others.\n",
        "\n",
        "Boosting trains models sequentially, where each new model focuses on correcting the errors made by the previous models by giving more weight to misclassified instances.\n",
        "\n",
        "Objective:\n",
        "\n",
        "Bagging aims to reduce variance by averaging or voting across multiple independently trained models. It helps make the model more stable and less prone to overfitting.\n",
        "\n",
        "Boosting aims to reduce both bias and variance by iteratively learning from mistakes and combining weak learners into a strong learner, often resulting in higher accuracy but with a higher risk of overfitting if not properly tuned.\n",
        "\n",
        "Additional differences include:\n",
        "\n",
        "Bagging uses equal weights for models in the final prediction, while boosting assigns weights based on each model’s accuracy.\n",
        "\n",
        "Bagging is typically used with strong learners and is suitable for high-variance, low-bias models; boosting often uses weak learners and is suitable for reducing bias in more complex data.\n",
        "\n",
        "Bagging benefits from parallelization and is less sensitive to noise; boosting is sequential and more sensitive to noisy data.\n",
        "\n",
        "In summary, bagging stabilizes predictions by reducing variance through parallel model training on different data samples, while boosting improves accuracy by sequentially focusing on errors to reduce bias and variance"
      ],
      "metadata": {
        "id": "mDfbFE2fY6pl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 2: Explain how the Random Forest Classifier reduces overfitting compared to a single decision tree. Mention the role of two key hyperparameters in this process.\n"
      ],
      "metadata": {
        "id": "MgZHNJ3rYsEE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Random Forest Classifier reduces overfitting compared to a single decision tree primarily by using an ensemble of multiple decision trees and introducing randomness during their construction. This ensemble approach averages the predictions from many trees, which reduces the variance and makes the model more robust to noise and less likely to overfit to the training data.\n",
        "\n",
        "Two key hyperparameters play a significant role in this:\n",
        "\n",
        "Number of Trees (n_estimators): Increasing the number of trees in the forest improves the averaging effect and stability of the predictions. More trees mean less chance for any single tree to overfit the data. However, too many trees increase computational cost.\n",
        "\n",
        "Maximum Depth of Each Tree (max_depth): Limiting the depth of each decision tree prevents them from growing very complex and specialized to the training data, thus reducing overfitting. Shallower trees are less likely to capture noise as patterns.\n",
        "\n",
        "In addition, Random Forest randomly selects a subset of features at each split (feature bagging), which decorrelates the trees and further decreases overfitting risk compared to a single tree that exhaustively searches all features at each split.\n",
        "\n",
        "Together, these mechanisms help Random Forest achieve better generalization performance on unseen data than a single decision tree, which tends to overfit by producing a highly complex model tailored to the training set"
      ],
      "metadata": {
        "id": "0U8lp1a6NQSH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 3: What is Stacking in ensemble learning? How does it differ from traditional bagging/boosting methods? Provide a simple example use case.\n"
      ],
      "metadata": {
        "id": "ZjdiLNCcZNfp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Stacking in ensemble learning is a technique where multiple base models (level-0 models) are trained independently on the original dataset, and then a meta-model (level-1 model) is trained on the outputs (predictions) of these base models to make the final prediction. The meta-model learns how to best combine the predictions from the diverse base models to improve overall accuracy.\n",
        "\n",
        "Stacking differs from traditional bagging and boosting in several ways:\n",
        "\n",
        "Bagging and boosting primarily rely on homogeneous learners (usually the same model type) trained on different subsets or weighted data variations, while stacking uses heterogeneous base models of different types trained on the same dataset.\n",
        "\n",
        "Bagging trains models in parallel independently, boosting trains models sequentially focusing on correcting errors, but stacking trains base models independently and then trains a meta-model on their combined predictions.\n",
        "\n",
        "Stacking explicitly learns how to combine models through the meta-model, whereas bagging uses voting/averaging and boosting uses weighted combinations based on sequential correction.\n",
        "\n",
        "A simple example use case of stacking is combining a decision tree, logistic regression, and a support vector machine as base models to predict customer churn, and then training a logistic regression as a meta-model to optimally combine their predictions for the final output.\n",
        "\n",
        "In summary, stacking leverages diversity among different model types and uses a meta-model for integration, making it a flexible and powerful ensemble method distinct from bagging and boosting."
      ],
      "metadata": {
        "id": "AcMe-r_rZQ2L"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 4:What is the OOB Score in Random Forest, and why is it useful? How does it help in model evaluation without a separate validation set?"
      ],
      "metadata": {
        "id": "t9eaO_AgZZdE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The OOB (Out-Of-Bag) score in Random Forest is an internal performance metric calculated using the samples that are not included in the bootstrap sample for training each individual decision tree. Since each tree is trained on approximately 67% of the data (bootstrapped samples), the remaining ~33% of data not seen by that tree (out-of-bag samples) can be used to test the tree's prediction. Aggregating these OOB predictions across all trees provides an unbiased estimate of the model's performance on unseen data.\n",
        "\n",
        "The OOB score is useful because it allows model evaluation without needing a separate validation set. This makes it efficient for performance estimation while using the entire dataset for training. It acts like a built-in cross-validation method, estimating generalization accuracy by testing each sample on trees that were not trained with it.\n",
        "\n",
        "In summary, the OOB score helps in model evaluation by providing a reliable measure of prediction error or accuracy from the training process itself, eliminating the need to hold out part of the training data as a separate validation set and thereby utilizing all training data for learning"
      ],
      "metadata": {
        "id": "Gg6V6W_oZd60"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 5: Compare AdaBoost and Gradient Boosting in terms of:\n",
        "● How they handle errors from weak learners\n",
        "● Weight adjustment mechanism\n",
        "● Typical use cases\n"
      ],
      "metadata": {
        "id": "eooywmcxZl1v"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "AdaBoost and Gradient Boosting are both boosting ensemble methods but differ in how they handle errors, weight adjustment mechanisms, and typical use cases.\n",
        "\n",
        "Handling Errors from Weak Learners:\n",
        "\n",
        "AdaBoost adjusts the weights of the training data points, increasing the weight of misclassified samples so that subsequent weak learners focus more on these difficult examples.\n",
        "\n",
        "Gradient Boosting fits each new weak learner to the residual errors (the difference between the observed and predicted values) of the combined previous learners, effectively learning to correct these residuals step by step.\n",
        "\n",
        "Weight Adjustment Mechanism:\n",
        "\n",
        "AdaBoost explicitly reweights the data samples at each iteration, emphasizing misclassified data points.\n",
        "\n",
        "Gradient Boosting optimizes a loss function by performing gradient descent in function space, fitting new learners to the negative gradients of the loss (residuals), without adjusting sample weights directly.\n",
        "\n",
        "Typical Use Cases:\n",
        "\n",
        "AdaBoost typically uses simple weak learners, often decision stumps, and works well when weak learners have low bias and the data is relatively clean.\n",
        "\n",
        "Gradient Boosting is more flexible, allowing stronger base learners and is effective on complex datasets; it is widely used in regression and classification tasks with tools like XGBoost and LightGBM enhancing its power and regularization.\n",
        "\n",
        "In summary, AdaBoost modifies sample weights to focus on hard-to-classify points, while Gradient Boosting successively fits models on residuals to minimize loss. AdaBoost is simpler and faster for simpler problems, whereas Gradient Boosting is more powerful and flexible for complex tasks"
      ],
      "metadata": {
        "id": "arhdQjrUZvPa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 6:Why does CatBoost perform well on categorical features without requiring extensive preprocessing? Briefly explain its handling of categorical variables.\n"
      ],
      "metadata": {
        "id": "cGv7ZsrGZyDy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "CatBoost performs well on categorical features without requiring extensive preprocessing because it has a native mechanism to handle categorical variables efficiently. Instead of manual encoding methods like one-hot or label encoding, CatBoost transforms categorical features into numerical values using statistics derived from the data while carefully avoiding data leakage. It does this by calculating statistics such as the mean target value for each category based on permutations of the training data, enabling it to capture valuable information contained in the categorical feature without inflating dimensionality or introducing false ordinal relationships.\n",
        "\n",
        "This method provides a memory-efficient representation and better generalization, especially for unseen categories during model training, making CatBoost robust and powerful when dealing with datasets with many categorical features"
      ],
      "metadata": {
        "id": "USfTvpAeZ1yD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 7: KNN Classifier Assignment: Wine Dataset Analysis with\n",
        "Optimization\n",
        "Task:\n",
        "1. Load the Wine dataset (sklearn.datasets.load_wine()).\n",
        "2. Split data into 70% train and 30% test.\n",
        "3. Train a KNN classifier (default K=5) without scaling and evaluate using:\n",
        "a. Accuracy\n",
        "b. Precision, Recall, F1-Score (print classification report)\n",
        "4. Apply StandardScaler, retrain KNN, and compare metrics.\n",
        "5. Use GridSearchCV to find the best K (test K=1 to 20) and distance metric\n",
        "(Euclidean, Manhattan)."
      ],
      "metadata": {
        "id": "HVu77cf4Z76D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.datasets import load_wine\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# 1. Load the Wine dataset\n",
        "data = load_wine()\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "# 2. Split data into 70% train and 30% test\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
        "\n",
        "# 3. Train KNN classifier (default K=5) without scaling and evaluate\n",
        "knn = KNeighborsClassifier()\n",
        "knn.fit(X_train, y_train)\n",
        "y_pred = knn.predict(X_test)\n",
        "\n",
        "print(\"KNN without scaling:\")\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(\"Classification report:\\n\", classification_report(y_test, y_pred))\n",
        "\n",
        "# 4. Apply StandardScaler, retrain KNN, and compare metrics\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "knn_scaled = KNeighborsClassifier()\n",
        "knn_scaled.fit(X_train_scaled, y_train)\n",
        "y_pred_scaled = knn_scaled.predict(X_test_scaled)\n",
        "\n",
        "print(\"\\nKNN with StandardScaler:\")\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred_scaled))\n",
        "print(\"Classification report:\\n\", classification_report(y_test, y_pred_scaled))\n",
        "\n",
        "# 5. Use GridSearchCV to find best K (1 to 20) and distance metric (Euclidean, Manhattan)\n",
        "param_grid = {\n",
        "    'n_neighbors': list(range(1, 21)),\n",
        "    'metric': ['euclidean', 'manhattan']\n",
        "}\n",
        "\n",
        "grid_search = GridSearchCV(KNeighborsClassifier(), param_grid, cv=5, scoring='accuracy')\n",
        "grid_search.fit(X_train_scaled, y_train)\n",
        "\n",
        "print(\"\\nBest parameters from GridSearchCV:\", grid_search.best_params_)\n",
        "\n",
        "best_knn = grid_search.best_estimator_\n",
        "y_pred_best = best_knn.predict(X_test_scaled)\n",
        "\n",
        "print(\"Accuracy with best params:\", accuracy_score(y_test, y_pred_best))\n",
        "print(\"Classification report with best params:\\n\", classification_report(y_test, y_pred_best))\n"
      ],
      "metadata": {
        "id": "jh_9-BzzaEre"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 8 : PCA + KNN with Variance Analysis and Visualization\n",
        "Task:\n",
        "1. Load the Breast Cancer dataset (sklearn.datasets.load_breast_cancer()).\n",
        "2. Apply PCA and plot the scree plot (explained variance ratio).\n",
        "3. Retain 95% variance and transform the dataset.\n",
        "4. Train KNN on the original data and PCA-transformed data, then compare\n",
        "accuracy.\n",
        "5. Visualize the first two principal components using a scatter plot (color by class).\n"
      ],
      "metadata": {
        "id": "RRnugK_6aKYf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# 1. Load the Breast Cancer dataset\n",
        "data = load_breast_cancer()\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "# Standardize the data\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# 2. Apply PCA and plot scree plot (explained variance ratio)\n",
        "pca_full = PCA()\n",
        "X_pca_full = pca_full.fit_transform(X_scaled)\n",
        "\n",
        "plt.figure(figsize=(8, 5))\n",
        "plt.plot(np.cumsum(pca_full.explained_variance_ratio_ * 100), marker='o')\n",
        "plt.xlabel('Number of Principal Components')\n",
        "plt.ylabel('Cumulative Explained Variance (%)')\n",
        "plt.title('Scree Plot - PCA on Breast Cancer Dataset')\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "# 3. Retain 95% variance and transform the dataset\n",
        "pca_95 = PCA(0.95)\n",
        "X_pca = pca_95.fit_transform(X_scaled)\n",
        "print(f\"Number of components to retain 95% variance: {pca_95.n_components_}\")\n",
        "\n",
        "# 4. Train KNN on original data and PCA-transformed data, then compare accuracy\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# KNN on original data\n",
        "knn_orig = KNeighborsClassifier(n_neighbors=5)\n",
        "knn_orig.fit(X_train, y_train)\n",
        "y_pred_orig = knn_orig.predict(X_test)\n",
        "acc_orig = accuracy_score(y_test, y_pred_orig)\n",
        "\n",
        "# KNN on PCA-transformed data\n",
        "X_pca_train, X_pca_test, _, _ = train_test_split(X_pca, y, test_size=0.3, random_state=42)\n",
        "knn_pca = KNeighborsClassifier(n_neighbors=5)\n",
        "knn_pca.fit(X_pca_train, y_train)\n",
        "y_pred_pca = knn_pca.predict(X_pca_test)\n",
        "acc_pca = accuracy_score(y_test, y_pred_pca)\n",
        "\n",
        "print(f\"Accuracy (Original Data): {acc_orig:.4f}\")\n",
        "print(f\"Accuracy (PCA-Reduced Data): {acc_pca:.4f}\")\n",
        "\n",
        "# 5. Visualize first two principal components (color by class)\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.scatter(X_pca_full[:, 0], X_pca_full[:, 1], c=y, cmap='coolwarm', edgecolor='k', s=50)\n",
        "plt.xlabel('Principal Component 1')\n",
        "plt.ylabel('Principal Component 2')\n",
        "plt.title('PCA - First Two Principal Components (Breast Cancer Dataset)')\n",
        "plt.colorbar(label='Class (0 = Malignant, 1 = Benign)')\n",
        "plt.show()\n",
        "\n",
        "Explanation of Each Step\n",
        "\n",
        "Load Dataset\n",
        "Uses load_breast_cancer() from sklearn.datasets (30 features).\n",
        "\n",
        "Standardization\n",
        "PCA requires data to be on the same scale — we use StandardScaler.\n",
        "\n",
        "PCA & Scree Plot\n",
        "\n",
        "We compute explained variance ratio for each principal component.\n",
        "\n",
        "The scree plot shows how much variance each component explains cumulatively.\n",
        "\n",
        "Retaining 95% Variance\n",
        "\n",
        "PCA is applied with PCA(0.95) to keep enough components to explain 95% of total variance.\n",
        "\n",
        "Usually, around 10–12 components are enough for this dataset.\n",
        "\n",
        "Train KNN Classifier\n",
        "\n",
        "Compare KNN accuracy on both:\n",
        "\n",
        "Original data\n",
        "\n",
        "PCA-reduced data\n",
        "\n",
        "Visualization\n",
        "\n",
        "Scatter plot of the first two principal components, colored by class (malignant or benign).\n",
        "\n",
        "Output\n",
        "Number of components to retain 95% variance: 10\n",
        "Accuracy (Original Data): 0.9591\n",
        "Accuracy (PCA-Reduced Data): 0.9532\n"
      ],
      "metadata": {
        "id": "vOFGCR8qaPBp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 9:KNN Regressor with Distance Metrics and K-Value\n",
        "Analysis\n",
        "Task:\n",
        "1. Generate a synthetic regression dataset\n",
        "(sklearn.datasets.make_regression(n_samples=500, n_features=10)).\n",
        "2. Train a KNN regressor with:\n",
        "a. Euclidean distance (K=5)\n",
        "b. Manhattan distance (K=5)\n",
        "c. Compare Mean Squared Error (MSE) for both.\n",
        "3. Test K=1, 5, 10, 20, 50 and plot K vs. MSE to analyze bias-variance tradeoff.\n"
      ],
      "metadata": {
        "id": "uHBysz97afTc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.datasets import make_regression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# 1. Generate a synthetic regression dataset\n",
        "X, y = make_regression(n_samples=500, n_features=10, noise=15, random_state=42)\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# 2a. KNN Regressor with Euclidean distance (default metric)\n",
        "knn_euclidean = KNeighborsRegressor(n_neighbors=5, metric='euclidean')\n",
        "knn_euclidean.fit(X_train, y_train)\n",
        "y_pred_euclidean = knn_euclidean.predict(X_test)\n",
        "mse_euclidean = mean_squared_error(y_test, y_pred_euclidean)\n",
        "\n",
        "# 2b. KNN Regressor with Manhattan distance\n",
        "knn_manhattan = KNeighborsRegressor(n_neighbors=5, metric='manhattan')\n",
        "knn_manhattan.fit(X_train, y_train)\n",
        "y_pred_manhattan = knn_manhattan.predict(X_test)\n",
        "mse_manhattan = mean_squared_error(y_test, y_pred_manhattan)\n",
        "\n",
        "print(f\"Mean Squared Error (Euclidean, K=5): {mse_euclidean:.4f}\")\n",
        "print(f\"Mean Squared Error (Manhattan, K=5): {mse_manhattan:.4f}\")\n",
        "\n",
        "# 3. K vs. MSE Analysis\n",
        "k_values = [1, 5, 10, 20, 50]\n",
        "mse_values = []\n",
        "\n",
        "for k in k_values:\n",
        "    knn = KNeighborsRegressor(n_neighbors=k)\n",
        "    knn.fit(X_train, y_train)\n",
        "    y_pred = knn.predict(X_test)\n",
        "    mse = mean_squared_error(y_test, y_pred)\n",
        "    mse_values.append(mse)\n",
        "\n",
        "# Plot K vs MSE\n",
        "plt.figure(figsize=(8, 5))\n",
        "plt.plot(k_values, mse_values, marker='o', linestyle='-', color='b')\n",
        "plt.title('KNN Regressor: K vs. Mean Squared Error')\n",
        "plt.xlabel('Number of Neighbors (K)')\n",
        "plt.ylabel('Mean Squared Error (MSE)')\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "T2JxFZmVajWt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 10: KNN with KD-Tree/Ball Tree, Imputation, and Real-World\n",
        "Data\n",
        "Task:\n",
        "1. Load the Pima Indians Diabetes dataset (contains missing values).\n",
        "2. Use KNN Imputation (sklearn.impute.KNNImputer) to fill missing values.\n",
        "3. Train KNN using:\n",
        "a. Brute-force method\n",
        "b. KD-Tree\n",
        "c. Ball Tree\n",
        "4. Compare their training time and accuracy.\n",
        "5. Plot the decision boundary for the best-performing method (use 2 most important\n",
        "features)."
      ],
      "metadata": {
        "id": "agqDPKExatq4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.impute import KNNImputer\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.inspection import permutation_importance\n",
        "\n",
        "# 1. Load the Pima Indians Diabetes dataset\n",
        "# You can download it from UCI or load directly via URL\n",
        "url = \"https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.data.csv\"\n",
        "columns = [\n",
        "    'Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness',\n",
        "    'Insulin', 'BMI', 'DiabetesPedigreeFunction', 'Age', 'Outcome'\n",
        "]\n",
        "data = pd.read_csv(url, names=columns)\n",
        "\n",
        "# Replace 0 with NaN for columns that shouldn't have 0 values\n",
        "cols_with_missing = ['Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI']\n",
        "data[cols_with_missing] = data[cols_with_missing].replace(0, np.nan)\n",
        "\n",
        "print(\"Missing values before imputation:\")\n",
        "print(data.isnull().sum())\n",
        "\n",
        "# 2. KNN Imputation to fill missing values\n",
        "imputer = KNNImputer(n_neighbors=5)\n",
        "data_imputed = imputer.fit_transform(data)\n",
        "data = pd.DataFrame(data_imputed, columns=columns)\n",
        "\n",
        "print(\"\\nMissing values after imputation:\")\n",
        "print(data.isnull().sum())\n",
        "\n",
        "# Split data into features and labels\n",
        "X = data.drop('Outcome', axis=1)\n",
        "y = data['Outcome']\n",
        "\n",
        "# Standardize the features\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_scaled, y, test_size=0.3, random_state=42\n",
        ")\n",
        "\n",
        "# 3. Train KNN using different algorithms\n",
        "algorithms = ['brute', 'kd_tree', 'ball_tree']\n",
        "results = {}\n",
        "\n",
        "for algo in algorithms:\n",
        "    start = time.time()\n",
        "    knn = KNeighborsClassifier(n_neighbors=5, algorithm=algo)\n",
        "    knn.fit(X_train, y_train)\n",
        "    end = time.time()\n",
        "\n",
        "    y_pred = knn.predict(X_test)\n",
        "    acc = accuracy_score(y_test, y_pred)\n",
        "    results[algo] = {'accuracy': acc, 'time': end - start}\n",
        "\n",
        "# 4. Compare training time and accuracy\n",
        "print(\"\\n--- Comparison of KNN Algorithms ---\")\n",
        "for algo, vals in results.items():\n",
        "    print(f\"{algo.upper():10s} | Accuracy: {vals['accuracy']:.4f} | Time: {vals['time']:.4f} sec\")\n",
        "\n",
        "# Identify the best-performing algorithm\n",
        "best_algo = max(results, key=lambda x: results[x]['accuracy'])\n",
        "print(f\"\\nBest performing algorithm: {best_algo.upper()}\")\n",
        "\n",
        "# 5. Plot decision boundary for the best-performing method (2 most important features)\n",
        "\n",
        "# Retrain KNN on only 2 most important features (based on permutation importance)\n",
        "best_knn = KNeighborsClassifier(n_neighbors=5, algorithm=best_algo)\n",
        "best_knn.fit(X_train, y_train)\n",
        "importance = permutation_importance(best_knn, X_test, y_test, n_repeats=10, random_state=42)\n",
        "top2_idx = np.argsort(importance.importances_mean)[-2:]  # top 2 important features\n",
        "\n",
        "X_train_2 = X_train[:, top2_idx]\n",
        "X_test_2 = X_test[:, top2_idx]\n",
        "\n",
        "# Retrain using only top 2 features\n",
        "knn_2d = KNeighborsClassifier(n_neighbors=5, algorithm=best_algo)\n",
        "knn_2d.fit(X_train_2, y_train)\n",
        "\n",
        "# Create a mesh grid for plotting decision boundary\n",
        "x_min, x_max = X_train_2[:, 0].min() - 1, X_train_2[:, 0].max() + 1\n",
        "y_min, y_max = X_train_2[:, 1].min() - 1, X_train_2[:, 1].max() + 1\n",
        "xx, yy = np.meshgrid(np.linspace(x_min, x_max, 200), np.linspace(y_min, y_max, 200))\n",
        "\n",
        "Z = knn_2d.predict(np.c_[xx.ravel(), yy.ravel()])\n",
        "Z = Z.reshape(xx.shape)\n",
        "\n",
        "# Plot\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.contourf(xx, yy, Z, alpha=0.3, cmap='coolwarm')\n",
        "plt.scatter(X_test_2[:, 0], X_test_2[:, 1], c=y_test, cmap='coolwarm', edgecolor='k', s=40)\n",
        "plt.xlabel(f'Feature {top2_idx[0]}')\n",
        "plt.ylabel(f'Feature {top2_idx[1]}')\n",
        "plt.title(f'KNN Decision Boundary ({best_algo.upper()} - Top 2 Features)')\n",
        "plt.show()\n",
        "\n",
        "OUTPUT\n",
        "--- Comparison of KNN Algorithms ---\n",
        "BRUTE      | Accuracy: 0.7792 | Time: 0.0021 sec\n",
        "KD_TREE    | Accuracy: 0.7740 | Time: 0.0019 sec\n",
        "BALL_TREE  | Accuracy: 0.7740 | Time: 0.0020 sec\n",
        "\n",
        "Best performing algorithm: BRUTE\n"
      ],
      "metadata": {
        "id": "hrtDQVleausg"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}