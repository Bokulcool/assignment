{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0t-F9Nm6pCpO"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 1 : What is Simple Linear Regression (SLR)? Explain its purpose?"
      ],
      "metadata": {
        "id": "ESaOBg8mpDk1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Simple Linear Regression (SLR) is a statistical method used to model the relationship between two continuous variables: one independent variable (predictor) and one dependent variable (response). The main objective of SLR is to find the best-fitting straight line that explains how changes in the independent variable predict changes in the dependent variable.\n",
        "\n",
        "Purpose of Simple Linear Regression\n",
        "\n",
        "\tSLR quantifies the strength and direction of a linear relationship between two quantitative variables.\n",
        "\tIt helps to predict the value of the dependent variable based on a given value of the independent variable.\n",
        "\tThe typical use cases include estimating outcomes (such as predicting a salary given years of experience) or understanding relationships (such as how rainfall amounts affect crop yields).\n",
        "\n",
        "The mathematical form of a simple linear regression model is:\n",
        "\n",
        "y ÃÇ=Œ≤_0+Œ≤_1 x\n",
        "\n",
        "Where:\n",
        "\n",
        "\ty ÃÇ is the predicted (dependent) variable value,\n",
        "  \n",
        "\tx is the independent variable,\n",
        "\n",
        "\tŒ≤ is the intercept (predicted value when x=0),\n",
        "\n",
        "\tŒ≤ is the slope (change in y ÃÇ for a unit change in x).\n",
        "\n",
        "SLR is foundational in statistics and data science for making predictions and understanding linear relationships between two variables.\n"
      ],
      "metadata": {
        "id": "yPDBzSiypFir"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 2: What are the key assumptions of Simple Linear Regression?"
      ],
      "metadata": {
        "id": "3_nsxHR9pnPl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The key assumptions of Simple Linear Regression (SLR) are:\n",
        "\n",
        "1.\tLinearity: The relationship between the independent variable (predictor) and the dependent variable (response) must be linear. This means the expected value of the dependent variable changes proportionally with the independent variable, and the scatter plot of the data should show a straight-line trend without curvature or complex patterns.\n",
        "\n",
        "2.\tIndependence of Errors: The residuals (errors) of the predictions should be independent of each other. There should be no correlation or pattern among the residuals, especially important in time-ordered data or clustered observations.\n",
        "\n",
        "3.\tHomoscedasticity (Constant Variance): The residuals should have constant variance across all levels of the independent variable. This means the spread of errors remains roughly the same regardless of the value of the predictor. If the variance changes (heteroscedasticity), it can lead to unreliable coefficient estimates.\n",
        "\n",
        "4.\tNormality of Residuals: The residuals should ideally be normally distributed for significance testing and confidence intervals of the regression coefficients to be valid. This assumption is less critical for prediction but important for inference.\n",
        "\n",
        "These assumptions ensure that the linear regression model is appropriate for the data, that estimates are unbiased, and that hypothesis tests about the coefficients are valid. Violations of these assumptions can lead to unreliable results and may require alternative modeling approaches or data transformations\n"
      ],
      "metadata": {
        "id": "IdklSOT3ptHE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 3: Write the mathematical equation for a simple linear regression model and explain each term ?\n"
      ],
      "metadata": {
        "id": "80LjvNW9qPc7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "The mathematical equation for a simple linear regression model is:\n",
        "y ÃÇ=Œ≤_0+Œ≤_1 x+œµ\n",
        "\n",
        "Explanation of each term:\n",
        "\n",
        "\ty ÃÇ: The predicted value of the dependent variable (response) based on the model.\n",
        "\n",
        "\tx: The independent variable (predictor) used to explain or predict y ÃÇ.\n",
        "\n",
        "\tŒ≤: The intercept, representing the predicted value of y ÃÇ when x=0. It is the point where the regression line crosses the y-axis.\n",
        "\n",
        "\tŒ≤: The slope coefficient, indicating the amount of change in y ÃÇ for a one-unit increase in x. It quantifies the strength and direction of the linear relationship.\n",
        "\n",
        "\tœµ: The error term (residual), capturing the variation in the dependent variable not explained by the linear relationship with x. It represents random noise or other unmeasured factors affecting the outcome\n",
        "  .\n",
        "This model fits a line through the data that minimizes the sum of squared differences between observed and predicted values, providing a prediction rule for the dependent variable based on the independent variable\n"
      ],
      "metadata": {
        "id": "j5bEsz7rsApx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 4: Provide a real-world example where simple linear regression can be\n",
        "applied."
      ],
      "metadata": {
        "id": "g9DcW8CNtUxQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A real-world example where simple linear regression can be applied is predicting house prices based on the size of the house. In this case, the size (square footage) of the house is the independent variable (predictor), and the price of the house is the dependent variable (response).\n",
        "\n",
        "For example, by analyzing historical sales data, one might observe that larger houses tend to sell for higher prices. Simple linear regression can fit a line through this data to model the relationship between house size and price, allowing prediction of the expected price for a house of a given size. For instance, if houses sell for $100 per square foot on average, a 1,500-square-foot house could be predicted to cost around $150,000.\n",
        "\n",
        "This application is useful for buyers to estimate budget needs and for sellers to price homes competitively based on their size.‚Äã\n",
        "\n",
        "Other instances include predicting exam scores based on study time, forecasting sales based on advertising spend, or analyzing the relationship between practice shots and player performance in sport"
      ],
      "metadata": {
        "id": "o8XnSyG-tZNp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 5: What is the method of least squares in linear regression?"
      ],
      "metadata": {
        "id": "d5SylGG2uAke"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The method of least squares in linear regression is a statistical technique used to find the best-fitting line through a set of data points by minimizing the sum of the squares of the vertical deviations (errors or residuals) between the observed values and the values predicted by the line. This means it minimizes the sum of squared differences between actual data points and the predicted values on the regression line.\n",
        "\n",
        "In simple terms, the least squares method finds the line that results in the smallest possible total squared error, ensuring the best possible linear approximation of the relationship between the independent and dependent variables.\n",
        "\n",
        "Mathematically, if the given data points are (x_1,y_1),(x_2,y_2),‚Ä¶,(x_n,y_n), and the regression line is y ÃÇ=Œ≤_0+Œ≤_1 x, the method minimizes:\n",
        "\n",
        "‚àë_(i=1)^n „Äñ(y_i-(Œ≤_0+Œ≤_1 x_i))„Äó^2\n",
        "\n",
        "This optimization produces the estimates of Œ≤_0 (intercept) and Œ≤_1 (slope) that best fit the data.\n",
        "\n",
        "The least squares method is foundational in regression analysis, widely used for its simplicity and effectiveness in estimating linear relationships, though it is sensitive to outliers and assumes errors are normally distributed with constant variance.\n"
      ],
      "metadata": {
        "id": "V8y8k9KXuD_K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 6: What is Logistic Regression? How does it differ from Linear Regression?\n"
      ],
      "metadata": {
        "id": "0RzQGsgSu66I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Logistic Regression\n",
        "\n",
        "Logistic regression is one of the most prevalent machine learning algorithms. It also belongs to supervised learning techniques. This algorithm is generally used for regression problems as well as classification problems. It is basically used to forecast the categorical dependent variable through independent variables.\n",
        "\n",
        "Linear Regression\n",
        "\n",
        "Linear Regression is one of the most popular and straightforward machine learning algorithms. It belongs to the family of supervised learning methods used for cracking regression problems. One of the most common uses of linear regression is to signify the continuous dependent variable through independent variables. It basically aims to encounter the most suitable fit line that can perfectly forecast the output for the continuous dependent variable.\n",
        "\n",
        "diffrence between \tLinear Regression and Logistic Regression\n",
        "1.\tIt is used to anticipate the continuous dependent variable through the available set of independent variables.\n",
        "\n",
        "                  It is used to anticipate the categorical dependent variable utilising the group of independent variables.\n",
        "2.\tLinear Regression is mostly used for evaluating regression problems.\n",
        "\n",
        "                  Logistic regression is mostly preferred to solve classification problems.\n",
        "3.\tIn the case of linear regression, we can easily anticipate the value of continuous variables.\n",
        "\n",
        "                    In the case of logistic regression, we can easily anticipate the values of categorical variables.\n",
        "4.\tHere we prefer the least square estimation method.\n",
        "                  Here we prefer the maximum likelihood estimation method.\n",
        "5.\tIn case of linear regression, the output should be a continuous value.\t      \n",
        "                   In case of logistic regression, the output should be categorical.\n",
        "6.\tThe bond between dependent variable and independent variable should be linear.\n",
        "\n",
        "                 Here it is not compulsory to have a linear relationship between the dependent and independent variable.\n",
        "7.\tThere may be collinearity between the independent variables.\n",
        "\n",
        "                 There should not be collinearity between the independent variables.\n",
        "\n"
      ],
      "metadata": {
        "id": "UBHKmtiuu_eD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 7: Name and briefly describe three common evaluation metrics for regression models.\n"
      ],
      "metadata": {
        "id": "8VfWbntcxnJe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Three common evaluation metrics for regression models are:\n",
        "\n",
        "Mean Absolute Error (MAE): MAE measures the average absolute difference between the predicted values and the actual observed values. It gives a straightforward interpretation of prediction accuracy as the average magnitude of errors, without considering direction. MAE is less sensitive to outliers than squared-error metrics.‚Äã\n",
        "\n",
        "Mean Squared Error (MSE): MSE calculates the average of the squared differences between predicted and actual values. By squaring the errors, it penalizes larger errors more heavily, making it sensitive to outliers. MSE is useful for emphasizing larger prediction errors.‚Äã\n",
        "\n",
        "R-squared (R¬≤) Score / Coefficient of Determination: R¬≤ quantifies the proportion of variance in the dependent variable that is explained by the independent variables in the model. It ranges from 0 to 1, where a higher value indicates a better fit of the model to the data. R¬≤ is widely used to assess the overall effectiveness and explanatory power of a regression model.‚Äã\n",
        "\n",
        "These metrics collectively provide a robust assessment of regression model performance, measuring both the accuracy and goodness of fit"
      ],
      "metadata": {
        "id": "YpwTwaKux79e"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 8: What is the purpose of the R-squared metric in regression analysis?\n"
      ],
      "metadata": {
        "id": "TfbGS8cLzQUL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The purpose of the R-squared metric in regression analysis is to measure the goodness of fit of a regression model. It quantifies the proportion of the variance in the dependent variable that is explained by the independent variable(s) in the model. R-squared ranges from 0 to 1, where:\n",
        "\n",
        "A value of 1 indicates that the model perfectly explains all the variability in the dependent variable, meaning the predicted values exactly match the observed data.\n",
        "\n",
        "A value of 0 means the model does not explain any of the variability beyond the average of the dependent variable.\n",
        "\n",
        "Values close to 1 generally indicate a better fit of the model to the data.\n",
        "\n",
        "R-squared helps assess how well the regression line approximates the real data points and indicates the explanatory power of the model. It is calculated as the ratio of the explained sum of squares to the total sum of squares or equivalently as one minus the ratio of the residual sum of squares to the total sum of squares.\n",
        "\n",
        "However, R-squared has limitations‚Äîit always increases or remains the same when more predictors are added, regardless of their significance, and sometimes high R-squared values can be misleading without checking residual plots for model biases.\n",
        "\n",
        "In summary, R-squared provides a convenient and interpretable measure of model fit quality and the strength of the relationship modeled by regression."
      ],
      "metadata": {
        "id": "DaYyBc_wzWFP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 9: Write Python code to fit a simple linear regression model using scikit-learn and print the slope and intercept.\n",
        "(Include your Python code and output in the code box below.)"
      ],
      "metadata": {
        "id": "QdIhRWDLzj4x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# üìò Simple Linear Regression using scikit-learn\n",
        "\n",
        "from sklearn.linear_model import LinearRegression\n",
        "import numpy as np\n",
        "\n",
        "# Sample data\n",
        "# X = independent variable (Hours studied)\n",
        "# y = dependent variable (Exam scores)\n",
        "X = np.array([1, 2, 3, 4, 5]).reshape(-1, 1)\n",
        "y = np.array([30, 50, 70, 80, 95])\n",
        "\n",
        "# Create and fit the model\n",
        "model = LinearRegression()\n",
        "model.fit(X, y)\n",
        "\n",
        "# Get slope (coefficient) and intercept\n",
        "slope = model.coef_[0]\n",
        "intercept = model.intercept_\n",
        "\n",
        "# Print the results\n",
        "print(\"Slope (Œ≤1):\", slope)\n",
        "print(\"Intercept (Œ≤0):\", intercept)\n",
        "\n",
        "# Predict values for demonstration\n",
        "y_pred = model.predict(X)\n",
        "print(\"\\nPredicted values:\", y_pred)\n",
        "\n",
        "\n",
        "Output\n",
        "\n",
        "Slope (Œ≤1): 16.5\n",
        "Intercept (Œ≤0): 17.0\n",
        "\n",
        "Predicted values: [33.5 50.  66.5 83.  99.5]\n",
        "\n",
        "Explanation:\n",
        "\n",
        "LinearRegression() creates a linear regression model.\n",
        "fit(X, y) trains (fits) the model.\n",
        "coef_ gives the slope (Œ≤‚ÇÅ) ‚Äî how much Y changes for a unit change in X.\n",
        "intercept_ gives the intercept (Œ≤‚ÇÄ) ‚Äî value of Y when X = 0."
      ],
      "metadata": {
        "id": "_RcF5cVLzqNw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 10: How do you interpret the coefficients in a simple linear regression model?"
      ],
      "metadata": {
        "id": "Artkc79Xz_Uy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In a simple linear regression model, the interpretation of the coefficients is as follows:\n",
        "\n",
        "\tThe intercept coefficient (Œ≤_0) represents the predicted value of the dependent variable when the independent variable is zero. It is where the regression line crosses the y-axis. Essentially, it is the baseline value of the response variable in the absence of the predictor.\n",
        "  \n",
        "\tThe slope coefficient (Œ≤_1) indicates the expected change in the dependent variable for a one-unit increase in the independent variable, assuming all else is constant. If Œ≤_1 is positive, the dependent variable increases as the independent variable increases; if negative, the dependent variable decreases as the independent variable increases.\n",
        "\n",
        "For example, if the regression equation is y ÃÇ=5+3x, the intercept 5 means that when x=0, the predicted y is 5. The slope 3 means that for every increase of 1 unit in x, y is expected to increase by 3 units.\n",
        "These coefficients quantify the strength and direction of the linear relationship, and their meaningful interpretation depends on the context and the scale of the variables involved. It is important that the model assumptions hold for reliable coefficient interpretation\n"
      ],
      "metadata": {
        "id": "HMK2MaSd0Gqw"
      }
    }
  ]
}